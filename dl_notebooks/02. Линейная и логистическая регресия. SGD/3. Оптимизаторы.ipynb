{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизаторы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический градиентный спуск вычисляет градиент функции потерь __по всей выборке__ и обновляет набор параметров $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta := \\theta − \\alpha \\nabla_\\theta J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдокод:\n",
    "\n",
    "```python\n",
    "theta += -learning_rate * d_theta\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При достаточно малой величине скорости обучения гарантированно делает шаг в сторону минимума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стохастический градиентный спуск вычисляет градиент функции потерь __по маленькой части выборки (вплоть до одного экземпляра выборки) - батчу__ и обновляет набор параметров $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta := \\theta − \\alpha \\nabla_\\theta J(\\theta, x^{(i:i+n)}, y^{(i:i+n)})\n",
    "$$\n",
    ", в частном случае:\n",
    "$$\n",
    "\\theta := \\theta − \\alpha \\nabla_\\theta J(\\theta, x^{(i)}, y^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственный разумный способ обрабатывать большие объемы данных, так как весь датасет, скорее всего, просто разом не поместится в оперативную память. Тем более это актуально при работе с изображениями. \n",
    "\n",
    "Кроме того, он используется для дообучения, когда нейронная сеть обучается уже во время своей работы (так называемое __онлайн-обучение__).\n",
    "\n",
    "Без минусов тоже не обошлось: использование такого рода оптимизатора не гарантирует каждый раз четкий шаг в сторону минимума функции потерь, а потому и обучение может проходить не так плавно, как в случае классического градиентного спуска, а с флуктуациями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sgd_fluctuation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не путаться, давайте говорить модно и молодёжно! \n",
    "\n",
    "* ___\"Стохастический градиентный спуск\"___ или ___\"эс-гэ-дэ\"___ предполагает, что обучение происходит по 1 экземпляру. \n",
    "* ___\"Мини-батч градиент дэсэнт\"___ или просто ___\"батч СГД\"___ предполагает, что обучение происходит по $n$ экземпляров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импульсное обновление (англ. \"momentum update\") - немного другой подход, который тоже ускоряет сходимость в глубоких сетях. Данный подход возник от физического представления оптимизационной проблемы. Текущее значение параметров - условное положение шарика, катающегося по поверхности функции потерь, как по холмам и ямкам. На него действует гравитация, и поэтому он ускоряется на склонах и замедляется, попадая в ямки. Интуитивно предполагается, что его импульс поможет ему достичь искомой точки минимума быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta J(\\theta) $$\n",
    "$$ \\theta := \\theta - v_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В терминах псевдокода:\n",
    "\n",
    "```python\n",
    "v = mu * v - learning_rate * d_theta  # изменение скорости\n",
    "theta += v # изменение положения\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/with_without_momentum.png\" width='50%'>\n",
    "На рисунке выше показано поведение SGD __без__ _(слева)_ механизма импульса и __с__ _(справа)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = SGD(momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульс Нестерова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импульс Нестерова (англ. \"Nesterov momentum\", он же \"Nesterov accelerated gradient\", или \"NAG\"). Говорят, что работает лучше! Но как?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте представим, что у нас уже есть импульс, и наш мячик катится. Обновление градиента по схеме выше состоит из двух компонент: непосредственно импульса и градиента. Тогда перед вычислением значения градиента мы можем заранее предсказать, куда катится шарик: это `mu + v`-часть в формуле выше (в англицкой литературе это называется _lookahead-vector_). И тогда мы можем вычислить градиент не от текущего положения, а от этого предсказанного, lookahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/nesterov.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta J(\\theta - \\gamma v_{t-1})  $$\n",
    "$$ \\theta := \\theta - v_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдокод:\n",
    "\n",
    "```python\n",
    "theta_ahead = theta + mu * v\n",
    "# вот здесь вычисляем градиент не от текущего положения theta, а от lookahead\n",
    "v = mu * v - learning_rate * d_theta_ahead  \n",
    "theta += v\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = SGD(nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тлен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем дольше идет процесс обучения, тем _вроде бы_ мы ближе стремимся к правильному решению, минимуму нашей функции потерь. А если это так, то необходимо со временем охлаждать наши темпы, постепенно уменьшая _скорость обучения $\\alpha$_. \n",
    "\n",
    "Этот механизм называется __learning rate decay__, или _..\"угасание\"? \"тление\"?..  скорости обучения_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариантов угасания много, но по умолчанию `SGD` из keras поддерживает один: линейное угасание с каждой эпохой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = SGD(decay=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во всех предыдущих случаях мы меняли обновляли все параметры глобально и разом. Это не всегда, однако, является лучшим решением.\n",
    "\n",
    "Давайте посмотрим на модификацию SGD, которую предложили [Duchi и его команда](http://jmlr.org/papers/v12/duchi11a.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cache += d_theta ** 2  # cache - вектор с обновлениями параметров\n",
    "theta += -learning_rate * d_theta / (sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемый `cache` используется после своего вычисления для того, чтобы в дальнейшем нормализовать обновления параметров theta. Если обновления некоторого параметра из вектора theta происходят часто, то благодаря делению на корень из `cache`, каждое из обновлений будет небольшим. И наоборот, редкие обновления будут осуществляться с меньшим штрафом.\n",
    "\n",
    "`eps` $= 10^{-4}...10^{-8}$ - использована, чтобы не разделить случайно на ноль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минус Adagrad в том, что он слишком жестко замедляет обновление, и обучение тормозится слишком рано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = Adagrad(epsilon=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp - попытка решения проблемы агрессивности Adagrad, и достаточно эффективная. Был использован механизм скользящего среднего, который может быть записан так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cache = decay_rate * cache + (1 - decay_rate) * d_theta**2\n",
    "theta += - learning_rate * d_theta / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложенный относительно недавно метод. Его обновление похоже на обновление в RMSProp, но обновления еще более гладкие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "m = beta1*m + (1-beta1)*d_theta\n",
    "v = beta2*v + (1-beta2)*(d_theta**2)\n",
    "theta += -learning_rate * m / (np.sqrt(v) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендованные авторами значения: `eps`$=10^{-8}$, `beta1`$=0.9$, `beta2`$=0.999$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как это выглядит?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Jaewan-Yun/optimizer-visualization\n",
    "\n",
    "Проследите внимательно, как ведет себя в разных ситуациях каждый. Сравните друг с другом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике рекомендуется пробовать прежде всего __Adam__, и __SGD + Nesterov Momentum__ как альтернативу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
